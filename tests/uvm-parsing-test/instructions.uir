.typedef @i1  = int<1>
.typedef @i8  = int<8>
.typedef @i16 = int<16>
.typedef @i32 = int<32>
.typedef @i64 = int<64>

.typedef @float  = float
.typedef @double = double

.typedef @void = void

.typedef @rv  = ref<@void>
.typedef @irv = iref<@void>
.typedef @wrv = weakref<@void>

.typedef @ri32 = ref<@i32>
.typedef @ri64 = ref<@i64>
.typedef @ii32 = iref<@i32>
.typedef @ii64 = iref<@i64>

.typedef @ii8 = iref<@i8>
.typedef @iii8 = iref<@ii8>

.funcsig @npnr_sig  = @void ()
.typedef @npnr_func = funcref<@npnr_sig>

.funcsig @iii_sig  = @i64 (@i64 @i64)
.typedef @iii_func = funcref<@iii_sig>

.typedef @thread    = threadref
.typedef @stack     = stackref
.typedef @tagref64  = tagref64

.typedef @4xfloat   = vector <@float 4>
.typedef @4xi32     = vector <@i32 4>
.typedef @2xdouble  = vector <@double 2>

.typedef @pv    = uptr<@void>
.typedef @pi32  = uptr<@i32>
.typedef @pi64  = uptr<@i64>
.typedef @npnr_fp = ufuncptr<@npnr_sig>
.typedef @iii_fp  = ufuncptr<@iii_sig>

.const @I8_0    <@i8>       = 0
.const @I16_0   <@i16>      = 0
.const @I32_0   <@i32>      = 0
.const @I64_0   <@i64>      = 0
.const @F_0     <@float>    = 0.0f
.const @D_0     <@float>    = 0.0d
.const @I8_1    <@i8>       = 1
.const @I16_1   <@i16>      = 1
.const @I32_1   <@i32>      = 1
.const @I64_1   <@i64>      = 1
.const @F_1     <@float>    = 1.0f
.const @D_1     <@float>    = 1.0d

.const @I32_2   <@i32>      = 2
.const @I64_2   <@i32>      = 2

.const @I64_42  <@i32>      = 42
.const @I64_43  <@i32>      = 43

.const @FALSE <@i1> = 0
.const @TRUE  <@i1> = 1

.const @NULLREF <@rv> = NULL

.const @VOID <@void> = NULL

.funcsig @intBinOpTest.sig = @void (@i32 @i32)
.funcdef @intBinOpTest VERSION %v1 <@intBinOpTest.sig> {
    %entry(<@i32> %p0 <@i32> %p1):
        %add  = ADD  <@i32> %p0 %p1
        %sub  = SUB  <@i32> %p0 %p1
        %mul  = MUL  <@i32> %p0 %p1
        %udiv = UDIV <@i32> %p0 %p1
        %sdiv = SDIV <@i32> %p0 %p1
        %urem = UREM <@i32> %p0 %p1
        %srem = SREM <@i32> %p0 %p1
        %shl  = SHL  <@i32> %p0 %p1
        %lshr = LSHR <@i32> %p0 %p1
        %ashr = ASHR <@i32> %p0 %p1
        %and  = AND  <@i32> %p0 %p1
        %or   = OR   <@i32> %p0 %p1
        %xor  = XOR  <@i32> %p0 %p1
        
        RET @VOID
}

.funcsig @fpBinOpTest.sig = @void (@double @double)
.funcdef @fpBinOpTest VERSION %v1 <@fpBinOpTest.sig> {
    %entry(<@double> %p0 <@double> %p1):
        %fadd = FADD <@double> %p0 %p1
        %fsub = FSUB <@double> %p0 %p1
        %fmul = FMUL <@double> %p0 %p1
        %fdiv = FDIV <@double> %p0 %p1
        %frem = FREM <@double> %p0 %p1
        
        RET @VOID
}

.funcsig @intCmpTest.sig = @void (@i64 @i64)
.funcdef @intCmpTest VERSION %v1 <@intCmpTest.sig> {
    %entry(<@i64> %p0 <@i64> %p1):
        %eq  = EQ  <@i64> %p0 %p1
        %ne  = NE  <@i64> %p0 %p1
        %ult = ULT <@i64> %p0 %p1
        %ule = ULE <@i64> %p0 %p1
        %ugt = UGT <@i64> %p0 %p1
        %uge = UGE <@i64> %p0 %p1
        %slt = SLT <@i64> %p0 %p1
        %sle = SLE <@i64> %p0 %p1
        %sgt = SGT <@i64> %p0 %p1
        %sge = SGE <@i64> %p0 %p1
        
        RET @VOID
}

.funcsig @fpCmpTest.sig = @void (@float @float)
.funcdef @fpCmpTest VERSION %v1 <@fpCmpTest.sig> {
    %entry(<@float> %p0 <@float> %p1):
        %ftrue  = FTRUE  <@float> %p0 %p1
        %ffalse = FFALSE <@float> %p0 %p1
        %ford = FORD <@float> %p0 %p1
        %foeq = FOEQ <@float> %p0 %p1
        %fone = FONE <@float> %p0 %p1
        %folt = FOLT <@float> %p0 %p1
        %fole = FOLE <@float> %p0 %p1
        %fogt = FOGT <@float> %p0 %p1
        %foge = FOGE <@float> %p0 %p1
        %funo = FUNO <@float> %p0 %p1
        %fueq = FUEQ <@float> %p0 %p1
        %fune = FUNE <@float> %p0 %p1
        %fult = FULT <@float> %p0 %p1
        %fule = FULE <@float> %p0 %p1
        %fugt = FUGT <@float> %p0 %p1
        %fuge = FUGE <@float> %p0 %p1
        
        RET @VOID
}

.funcsig @convTest.sig = @void (@i32 @i64 @float @double)
.funcdef @convTest VERSION %v1 <@convTest.sig> {
    %entry(<@i32> %p0 <@i64> %p1 <@float> %p2 <@double> %p3):
        %trunc  = TRUNC <@i64 @i32> %p1
        %zext   = ZEXT  <@i32 @i64> %p0
        %sext   = SEXT  <@i32 @i64> %p0

        %fptrunc = FPTRUNC <@double @float> %p3
        %fpext   = FPEXT   <@float @double> %p2

        %fptoui = FPTOUI <@double @i64> %p3
        %fptosi = FPTOSI <@double @i64> %p3
        %uitofp = UITOFP <@i64 @double> %p1
        %sitofp = SITOFP <@i64 @double> %p1

        %bitcast0 = BITCAST <@i32 @float>  %p0
        %bitcast1 = BITCAST <@i64 @double> %p1
        %bitcast2 = BITCAST <@float @i32>  %p2
        %bitcast3 = BITCAST <@double @i64> %p3

        RET @VOID
}

.funcsig @refCastTest.sig = @void (@rv @irv @npnr_func)
.funcdef @refCastTest VERSION %v1 <@refCastTest.sig> {
    %entry(<@rv> %p0 <@irv> %p1 <@npnr_func> %p2):
        %refcast  = REFCAST <@rv @ri32> %p0
        %irefcast = REFCAST <@irv @ii64> %p1
        %funccast = REFCAST <@npnr_func @iii_func> %p2
        
        RET @VOID
}

.funcsig @ptrCastTest.sig = @void (@i64)
.funcdef @ptrCastTest VERSION %v1 <@ptrCastTest.sig> {
    %entry(<@i64> %p0):
        %ptrcast = PTRCAST <@i64 @pi64> %p0
        
        RET @VOID
}

.funcsig @select.sig = @void ()
.funcdef @select VERSION %v1 <@select.sig> {
    %entry():
        %select  = SELECT <@i1 @i32> @TRUE @I32_0 @I32_1

        RET @VOID
}

.funcsig @ctrlFlow.sig = @void (@i32)
.funcdef @ctrlFlow VERSION %v1 <@ctrlFlow.sig> {
    %entry(<@i32> %p0):
        %br1 = BRANCH %head(%p0)
    
    %head(<@i32> %x):
        %zero = EQ <@i32> %x @I32_0
        %br2 = BRANCH2 %zero %body(%x) %exit()
        
    %body(<@i32> %x):
        %switch = SWITCH <@i32> %x %other(%x) { @I32_1 %one(%x) @I32_2 %two(%x) }
    %one(<@i32> %x):
        %br3 = BRANCH %next(%x)
    %two(<@i32> %x):
        %br4 = BRANCH %next(%x)
    %other(<@i32> %x):
        %br5 = BRANCH %next(%x)
    %next(<@i32> %x):
        %i2 = SUB <@i32> %x @I32_1
        %br6 = BRANCH %head(%i2)
        
    %exit():
        RET @VOID
}


.funcdecl @callee1 <@npnr_sig>

.funcdef @callee2 VERSION %v1 <@iii_sig> {
    %entry(<@i64> %p0 <@i64> %p1):
        %rv = ADD <@i64> %p0 %p1
        %ret = RET %rv
}

.funcdef @callee3 VERSION %v1 <@iii_sig> {
    %entry(<@i64> %p0 <@i64> %p1):
        %exc = NEW <@double>
        %throw = THROW %exc
}

.funcdef @caller1 VERSION %v1 <@npnr_sig> {
    %entry():
        %v1 = CALL <@npnr_sig> @callee1 ()
        %v2 = CALL <@iii_sig> @callee2 (@I64_1 @I64_2)
        %v3 = CALL <@iii_sig> @callee3 (@I64_1 @I64_2) EXC(%cont(%v2 %v3) %catch())

    %cont(<@i64> %v2 <@i64> %v3):
        %v4 = CALL <@npnr_sig> @callee1 () KEEPALIVE(%v2 %v3)
        %v5 = CALL <@iii_sig> @callee3 (%v3 %v3) EXC(%cont2() %catch()) KEEPALIVE(%v2)

    %cont2():
        %retv = RET @VOID

    %catch() [%exc]:
        RET @VOID
}

.funcdef @caller2 VERSION %v1 <@iii_sig> {
    %entry(<@i64> %p0 <@i64> %p1):
        %tc = TAILCALL <@iii_sig> @callee2 (%p0 %p1)
}

// .typedef @sid = struct <@i64 @double>
// .typedef @rsid = ref<@sid>
// .const @sid1 <@sid> = {@I64_1 @D_1}
// 
// .const @v1 <@4xfloat> = VEC {@F_0 @F_0 @F_0 @F_0}
// .const @v2 <@4xfloat> = VEC {@F_1 @F_1 @F_1 @F_1}
// 
// .const @I32_4 <@i32> = 4
// .const @I32_6 <@i32> = 6
// .const @vshf <@4xi32> = VEC {@I32_0 @I32_2 @I32_4 @I32_6}
// 
// .funcdef @aggregate VERSION %v1 <@npnr_sig> () {
//     %entry:
//         %e0 = EXTRACTVALUE <@sid 0> @sid1
//         %e1 = EXTRACTVALUE <@sid 1> @sid1
//         %i0 = INSERTVALUE  <@sid 0> @sid1 @I64_0
//         %i1 = INSERTVALUE  <@sid 1> @sid1 @D_0
//         %ee0 = EXTRACTELEMENT <@4xfloat @i32> @v1 @I32_0
//         %ie0 = INSERTELEMENT  <@4xfloat @i32> @v1 @I32_1 @F_1
//         %sv0 = SHUFFLEVECTOR  <@4xfloat @4xi32> @v1 @v2 @vshf
//     
//         RET @VOID
// }
// 
// .typedef @al = array <@i64 10>
// .typedef @ral = ref<@al>
// .typedef @hic = hybrid <@i64 @i8>
// .typedef @rhic = ref<@hic>
// 
// .funcsig @memops.sig = @void (@i64 @i64)
// .funcdef @memops VERSION %v1 <@memops.sig> (%p0 %p1) {
//     %entry:
//         %new            = NEW <@i64>
//         %newhybrid      = NEWHYBRID <@hic @i64> %p0
//         %alloca         = ALLOCA <@i64 >
//         %allocahybrid   = ALLOCAHYBRID <@hic @i64> %p0
// 
//         %new_s          = NEW <@i64> EXC(%bb2 %handler)
//     %bb2:
//         %newhybrid_s    = NEWHYBRID <@hic @i64> %p0 EXC(%bb3 %handler)
//     %bb3:
//         %alloca_s       = ALLOCA <@i64 > EXC(%bb4 %handler)
//     %bb4:
//         %allocahybrid_s = ALLOCAHYBRID <@hic @i64> %p0 EXC(%bb5 %handler)
// 
//     %bb5:
//         %new2           = NEW <@sid>
//         %alloca2        = ALLOCA <@al>
//         
//         %getiref        = GETIREF <@sid> %new2
//         
//         %getfieldiref   = GETFIELDIREF <@sid 0> %getiref
//         %getelemiref    = GETELEMIREF <@al @i64> %alloca2 %p1
//         
//         %getfixedpartiref   = GETFIXEDPARTIREF <@hic> %allocahybrid
//         %getvarpartiref     = GETVARPARTIREF <@hic> %allocahybrid
//         
//         %shiftiref      = SHIFTIREF <@i8 @i64> %getvarpartiref %p1
//         
//         %load       = LOAD  <@i64> %alloca
//         %store      = STORE <@i64> %alloca @I64_42
//         %cmpxchg    = CMPXCHG SEQ_CST SEQ_CST <@i64> %alloca @I64_42 @I64_0
//         %cmpxchg_w  = CMPXCHG WEAK SEQ_CST SEQ_CST <@i64> %alloca @I64_42 @I64_0
//         %atomicrmw  = ATOMICRMW SEQ_CST ADD <@i64> %alloca @I64_43
// 
//         %load_s     = LOAD  <@i64> %alloca EXC(%bb6 %handler)
//     %bb6:
//         %store_s    = STORE <@i64> %alloca @I64_42 EXC(%bb7 %handler)
//     %bb7:
//         %cmpxchg_s  = CMPXCHG SEQ_CST SEQ_CST <@i64> %alloca @I64_42 @I64_0 EXC(%bb8 %handler)
//     %bb8:
//         %atomicrmw_s= ATOMICRMW SEQ_CST ADD <@i64> %alloca @I64_43 EXC(%bb9 %handler)
// 
//     %bb9:
//         %fence = FENCE SEQ_CST
//         
//         RET @VOID
// 
//     %handler:
//         RET @VOID
// }
// 
// .funcsig @memops_ptr.sig = @void (@i64 @i64)
// .funcdef @memops_ptr VERSION %v1 <@memops_ptr.sig> (%p0 %p1) {
//     %entry:
//         %new            = NEW <@i64>
//         %newhybrid      = NEWHYBRID <@hic @i64> %p0
//         %new2           = NEW <@sid>
//         %new3           = NEW <@al>
// 
//         %p              = COMMINST @uvm.native.pin <@ri64> (%new)
//         %ph             = COMMINST @uvm.native.pin <@rhic> (%newhybrid)
//         %p2             = COMMINST @uvm.native.pin <@rsid> (%new2)
//         %p3             = COMMINST @uvm.native.pin <@ral>  (%new3)
//         
//         %getfieldiref   = GETFIELDIREF PTR <@sid 0>   %p2
//         %getelemiref    = GETELEMIREF  PTR <@al @i64> %p3 %p1
//         
//         %getfixedpartiref   = GETFIXEDPARTIREF PTR <@hic> %ph
//         %getvarpartiref     = GETVARPARTIREF   PTR <@hic> %ph
//         
//         %shiftiref      = SHIFTIREF PTR <@i8 @i64> %getvarpartiref %p1
//         
//         %load       = LOAD  PTR <@i64> %p
//         %store      = STORE PTR <@i64> %p @I64_42
//         %cmpxchg    = CMPXCHG PTR SEQ_CST SEQ_CST <@i64> %p @I64_42 @I64_0
//         %atomicrmw  = ATOMICRMW PTR SEQ_CST ADD <@i64> %p @I64_43
//         
//         RET @VOID
// }
// 
// 
// .funcsig @memorder.sig = @void (@ii64)
// .funcdef @memorder VERSION %v1 <@memorder.sig> (%p0) {
//     %entry:
//         %l0 = LOAD NOT_ATOMIC   <@i64> %p0
//         %l1 = LOAD RELAXED      <@i64> %p0
//         %l2 = LOAD CONSUME      <@i64> %p0
//         %l3 = LOAD ACQUIRE      <@i64> %p0
//         %s4 = STORE RELEASE     <@i64> %p0 @I64_42
//         %c5 = CMPXCHG ACQ_REL ACQUIRE   <@i64> %p0 @I64_42 @I64_43
//         %l6 = LOAD SEQ_CST      <@i64> %p0
// 
//         RET @VOID
// }
// 
// .funcsig @atomicrmwops.sig = @void (@ii64 @i64)
// .funcdef @atomicrmwops VERSION %v1 <@atomicrmwops.sig> (%p0 %p1) {
//     %entry:
//         %old0 = ATOMICRMW ACQ_REL XCHG  <@i64> %p0 %p1
//         %old1 = ATOMICRMW ACQ_REL ADD   <@i64> %p0 %p1
//         %old2 = ATOMICRMW ACQ_REL SUB   <@i64> %p0 %p1
//         %old3 = ATOMICRMW ACQ_REL AND   <@i64> %p0 %p1
//         %old4 = ATOMICRMW ACQ_REL NAND  <@i64> %p0 %p1
//         %old5 = ATOMICRMW ACQ_REL OR    <@i64> %p0 %p1
//         %old6 = ATOMICRMW ACQ_REL XOR   <@i64> %p0 %p1
//         %old7 = ATOMICRMW ACQ_REL MAX   <@i64> %p0 %p1
//         %old8 = ATOMICRMW ACQ_REL MIN   <@i64> %p0 %p1
//         %old9 = ATOMICRMW ACQ_REL UMAX  <@i64> %p0 %p1
//         %olda = ATOMICRMW ACQ_REL UMIN  <@i64> %p0 %p1
// 
//         RET @VOID
// }
// 
// .funcdef @traps VERSION %v1 <@npnr_sig> () {
//     %entry:
//         %a  = ADD <@i64> @I64_42 @I64_43
//         %b  = SUB <@i64> @I64_42 @I64_43
//         %c  = MUL <@i64> @I64_42 @I64_43
// 
//         %tp     = TRAP <@i32> KEEPALIVE(%a)
//         %tp_s   = TRAP <@i64> EXC(%tp_s_cont %tp_s_exc) KEEPALIVE(%b)
// 
//     %tp_s_cont:
//         %wp     = WATCHPOINT 1 <@float> %wp_dis_cont %wp_ena_cont KEEPALIVE(%a)
//     
//     %wp_dis_cont:
//         %wp_s   = WATCHPOINT 2 <@double> %wp_s_dis_cont %wp_s_ena_cont WPEXC(%wp_s_exc) KEEPALIVE(%b)
// 
//     %wp_ena_cont:
//         RET @VOID
// 
//     %wp_s_dis_cont:
//         RET @VOID
// 
//     %wp_s_ena_cont:
//         RET @VOID
//     
//     %tp_s_exc:
//         %exc = LANDINGPAD
//         THROW %exc
//         
//     %wp_s_exc:
//         %exc2 = LANDINGPAD
//         THROW %exc2
// }
// 
// .funcsig @ccall_callee.sig = @void (@double)
// .typedef @ccall_callee_fp = funcptr<@ccall_callee.sig>
// 
// .funcsig @ccall.sig = @void (@ccall_callee_fp)
// .funcdef @ccall VERSION %v1 <@ccall.sig> (%p0) {
//     %entry:
//         %rv = CCALL #DEFAULT <@ccall_callee_fp @ccall_callee.sig> %p0 (@D_1)
//         
//         RET @VOID
// }
// 
// .funcsig @gen.sig = @void (@stack)
// .funcdef @gen VERSION %v1 <@npnr_sig> (%main) {
//     %entry:
//         %ss1 = SWAPSTACK %main RET_WITH <@void> PASS_VALUE <@i64> @I64_0
//         %ss2 = SWAPSTACK %main KILL_OLD THROW_EXC @NULLREF
//         THROW @NULLREF // unreachable
// }
// 
// .funcdef @swapstack VERSION %v1 <@npnr_sig> () {
//     %entry:
//         %curstack = COMMINST @uvm.current_stack
//         %coro = NEWSTACK <@iii_sig> @callee2 (%curstack) EXC(%cont %exc)
//         
//     %cont:
//         %ss1 = SWAPSTACK %coro RET_WITH <@i64> PASS_VOID KEEPALIVE(%curstack)
//         %ss2 = SWAPSTACK %coro RET_WITH <@i64> PASS_VOID EXC(%nor %exc)
// 
//     %nor:
//         RET @VOID
//     %exc:
//         RET @VOID
// }
// 
// .funcdef @comminst VERSION %v1 <@npnr_sig> () {
//     %entry:
//         %curstack = COMMINST @uvm.current_stack
//         %sta = NEWSTACK <@iii_sig> @callee2 (%curstack)
//         %thr = COMMINST @uvm.new_thread (%sta)
// 
//         %ex = COMMINST @uvm.native.expose [#DEFAULT] <[@npnr_sig]> (@swapstack)
// 
//         %th_ex = COMMINST @uvm.thread_exit
//         RET @VOID
// }
// */
